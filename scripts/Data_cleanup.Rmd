---
title: "Cleaning the Polynesian Rat SNP raw data file"
author: "Grace Saville"
date: "11/02/2022"
output: pdf_document
---

```{r setup, include=FALSE}
library(formatR)
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

# 1. Preamble 

```{r libraries}
library(plyr)
library(reshape)
getwd()
setwd("C:/Users/airhe/OneDrive/Documents/Masters/Project 3/kiore-project")
```

# 2. Loading the data

```{r loading raw data}
data <- read.delim("./data/Raw_data/Genotyping-007.010-01_SNP_Raw_data.tsv")
dim(data) #478 rows (specimens), 333 columns (SNP loci)
data[1,1:17] # SNP data in columns 17 to 333
```

```{r data check}
class(data[5,17]) # character
count(data$island.1) #  how many samples from each island there are
data[data$island.1 == "",] # checking why 2 "island.1" cells are blank
data[c(471,473),1:10] # the blanks are from Laos and Cambodia, therefore replacing the blanks with "Mainland"
data[471,"island.1"] <- "Mainland"
data[473,"island.1"] <- "Mainland"

x <- data # keeping "data" as backup original
```

# 3. Tidying SNP order

* I'm doing this to make R evaluation easier (e.g when checking for counts it does not count A:G and G:A separately)
```{r SNP arrangement}
dim(x) # 333 cols
count(unlist(x[,17:333]))
x[x == "T:A"] <- "A:T"
x[x == "C:A"] <- "A:C"
x[x == "G:A"] <- "A:G" 
x[x == "T:C"] <- "C:T"
x[x == "G:C"] <- "C:G"
x[x == "G:T"] <- "T:G"
count(unlist(x[,17:333])) # checking success
```


## Specimens per Island before data clean-up

```{r count per island 1}
count(data$island.1)
```

|Island|freq|
|:----:|:----:|
|Aotea (Great Barrier I)|10|
|Borneo|25|
|Doubtful Sound|1|
|Great Mercury Island|1|
|Halmahera|25|
|Hatutaa|21|
|Honuea|21|
|Kaikura Island|20|
|Kamaka|21|
|Kayangel|21|
|Late Island|21|
|Luzon|1|
|Mainland|5|
|Malenge|25|
|Mohotani|14|
|Motukawanui|21|
|New Britain|26|
|New Guinea|25|
|Normanby Island|25|
|Rakiura (Stewart Isl)|21|
|Reiono|21|
|Rimatuu (Tetiaroa)|21|
|Slipper Island|21|
|Sulawesi|25|
|Tahanea|20|
|Wake Island|20|


# 4. Removing SNP columns with no variation (invariant/monomorphic)

```{r invariant column search}
ncol(x) #333
monocols <- integer() # empty vector for the for loop
for (i in 17:333) {
  z <- length(unique(x[, i])) # no. of unique values in the row (looking for 1, or 2 if there's "?")
  if (z <= 3) {
    monocols <- append(monocols, i) # if z is as so, add the column number to the vector
  }
  rm(z)
} 
# tried with z <= 2 but no result, therefore tried z <= 3 and checked the results manually below.

monocols # 17  34  73  80  88  95  98 101 102 108 119 129 139 154 156 171 176 177 178 179 194 203 207 208 209 227 237 239 243 251 252 253 265 271 276 324 331
for (i in monocols) {
  print(count(x[,i]))
}
# none with only 1 unique SNP in each column ...? It's possible since the SNP loci were selected for their differences, but double check this 
```

```{r column deletion 1}
# x <- x[,-c(monocols)] # for removal of monomorphic columns

rm(i, monocols)
```

# 5. Removing columns (SNPs) with few samples

```{r removing sparse columns}
ncol(x) #333
percblank <- integer() # empty df for the for loop
for (i in 17:333) {
  y <- count(grepl("?", x[,i], fixed = TRUE)) # finds and counts freq of ?
  z <- signif((nrow(x)- y[1,2])/nrow(x)*100, 4) # percentage of ? in the column, to 4 signif digits. I used the number of rows-false outcomes instead of the true outcomes because some rows have no "?"s and result in errors.
    if (z > 60) 
      {percblank <- append(percblank, i) 
    }
  rm(z)
  rm(y)
}

percblank # 17  18  19  25  48  65  69  73  80  88  89  96 102 108 131 133 146 147 156 159 162 165 179 185 205 208 212 228 241 258 264 265 271 304 330
# checking:
# count(x[,212])
# 320/478
```

```{r column delction}
x <- x[,-c(percblank)] # removing columns listed above, with more than 60% missing data
ncol(x) #298

rm(i, percblank)
```

# 6. Removing rows (specimens) with few samples

```{r removing sparse rows}
x2 <- data.table::transpose(x) # transposing the df temporarily since count() doesn't work well on rows

ncol(x2) #478 specimens
percblank <- integer() # empty df for the for loop
for (i in 1:478) {
  y <- count(grepl("?", x2[,i], fixed = TRUE)) # finds and counts freq of "?"
  z <- signif((nrow(x2) - y[1,2]) / nrow(x2) * 100, 4) # percentage of ? in the specimen, to 4 signif digits. 
  # I used the no. rows-false outcomes instead of the true outcomes because some rows have no "?" and result in errors.
  if (z > 56)
    # 56 percent missing allowed because it gives 90% completeness (see below)
  {
    percblank <- append(percblank, i)
  }
  rm(z)
  rm(y)
}

percblank # 1   7   9  10  11  18  25  48  49  50  51  52  53  55  56  57  58  59  60  62  63  65  66  71  79 80  87  88  89  90  91  92  93  95  96  97 101 102 103 104 105 106 108 109 110 111 112 113 114 115 117 118 119 120 121 122 123 124 125 128 129 131 133 134 135 136 137 139 141 142 143 144 145 146 150 151 152 153 154 155 156 157 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 335
# checking work:
# count(x2[17:298,171])
# 185/298
```

```{r row deletion}
x <- x[-c(percblank),] # removing the rows listed (percblank) that have too many "?" from the df
nrow(x) #379
```

# 7. Saving

```{r check and save}
# checking the % of all "?"s in the df:
z <- count(grepl("?", unlist(x), fixed = TRUE))
signif(z[2,2]/(z[1,2]+z[2,2])*100, 4) # 9.723% "?"
100 - 9.723 # 90.277% complete df, ideal point where there is more than 90% completeness but not too many rows and columns removed (yet)

rm(i, percblank, x2, z)
getwd()
# save(list=ls(all=TRUE), file=".RData") # save RDATA for later use if necessary
write.csv(x, "./data/RStudio/ratsSNPs_halfclean.csv", row.names = FALSE)
```



